{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560725a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.automatic_mask_generator import SAM2AutomaticMaskGenerator\n",
    "\n",
    "from utils import (\n",
    "    download_model,\n",
    "    get_point_coord,\n",
    "    get_polygon,\n",
    "    show_points,\n",
    "    show_mask,\n",
    "    show_res_multi,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(annotation_name, image_dir):\n",
    "    image_name = \"_\".join(annotation_name.split(\"_\")[:-1])\n",
    "    image_file = image_dir.joinpath(image_name + \".jpg\")\n",
    "    if image_file.exists():\n",
    "        image = Image.open(image_file)\n",
    "        return np.array(image), image_file\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def save_image_masks(masks, image_name, results_dir):\n",
    "    save_dir = results_dir.joinpath(image_name)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for i, mask in enumerate(masks):\n",
    "        # mask is 3D: 1, y, x\n",
    "        mask_img = mask[0].astype(np.uint8) * 255\n",
    "        mask_img = Image.fromarray(mask_img)\n",
    "        mask_img.save(save_dir.joinpath(f\"{i:03d}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6e5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    img_area = img.shape[0] * img.shape[1]\n",
    "    for ann in sorted_anns:\n",
    "        if ann[\"area\"] > img_area / 2:\n",
    "            continue\n",
    "\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f5cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2a2f1b",
   "metadata": {},
   "source": [
    "Download the large SAM2 model's weights from here:\n",
    "https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_large.pt\n",
    "\n",
    "For all available models see here: https://github.com/facebookresearch/sam2?tab=readme-ov-file#download-checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdebb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import initialize, core\n",
    "\n",
    "core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# large sam2: works on gpu > 8g\n",
    "sam2_checkpoint = \"../models/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "config_dir = \"../models/\"\n",
    "\n",
    "# base sam2: smaller version\n",
    "#sam2_checkpoint = \"../../SAM2_models/checkpoints/sam2_hiera_base_plus.pt\"\n",
    "#model_cfg = \"sam2_hiera_b+.yaml\"\n",
    "\n",
    "with initialize(version_base=None, config_path=config_dir):\n",
    "    sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device, apply_postprocessing=False)\n",
    "\n",
    "#predictor = SAM2ImagePredictor(sam2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db09425",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = Path(\"../../data/training_data/1\")\n",
    "print(image_dir.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6da958",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"../data/20240813/VID_01_GP_50/VID_01_2023_GP__0.14.45.00.jpg\"\n",
    "\n",
    "image = np.array(\n",
    "    Image.open(image_file)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f1fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea94550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points_per_side: Optional[int] = 32,\n",
    "# points_per_batch: int = 64,\n",
    "# pred_iou_thresh: float = 0.88,\n",
    "# stability_score_thresh: float = 0.95,\n",
    "# stability_score_offset: float = 1.0,\n",
    "# box_nms_thresh: float = 0.7,\n",
    "# crop_n_layers: int = 0,\n",
    "# crop_nms_thresh: float = 0.7,\n",
    "# crop_overlap_ratio: float = 512 / 1500,\n",
    "# crop_n_points_downscale_factor: int = 1,\n",
    "# point_grids: Optional[List[np.ndarray]] = None,\n",
    "# min_mask_region_area: int = 0,\n",
    "# output_mode: str = \"binary_mask\",\n",
    "\n",
    "mask_generator = SAM2AutomaticMaskGenerator(\n",
    "    model=sam2_model,\n",
    "    points_per_side=64,\n",
    "    pred_iou_thresh=0.87,\n",
    "    stability_score_thresh=0.80,\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=3,\n",
    "    crop_nms_thresh=0.7,\n",
    "    min_mask_region_area=500,  # Requires open-cv to run post-processing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4252b6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = mask_generator.generate(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09637b2",
   "metadata": {},
   "source": [
    "Mask generation returns a list over masks, where each mask is a dictionary containing various data about the mask. These keys are:\n",
    "* `segmentation` : the mask\n",
    "* `area` : the area of the mask in pixels\n",
    "* `bbox` : the boundary box of the mask in XYWH format\n",
    "* `predicted_iou` : the model's own prediction for the quality of the mask\n",
    "* `point_coords` : the sampled input point that generated this mask\n",
    "* `stability_score` : an additional measure of mask quality\n",
    "* `crop_box` : the crop of the image used to generate this mask in XYWH format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b9d6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(masks))\n",
    "print(masks[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "show_anns(masks)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
